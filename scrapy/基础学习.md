### 进阶学习

目录

    scrapy.cfg  （配置参数）
    myproject/
        __init__.py
        items.py
        middlewares.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            spider1.py
            spider2.py
            ...

### scrapy.cfg
项目之间共享根目录[settings]在scrapy.cfg文件，scrapy命令行工具将使用这些default设置

    [settings]
    default = myproject1.settings
    project1 = myproject1.settings
    project2 = myproject2.settings

使用SCRAPY_PROJECT环境变量指定scrapy要使用的其他项目：

    $ scrapy settings --get BOT_NAME
    Project 1 Bot
    $ export SCRAPY_PROJECT=project2
    $ scrapy settings --get BOT_NAME
    Project 2 Bot

主要命令

    scrapy startproject myproject [project_dir] 创建项目
    scrapy genspider example example.com    创建爬虫
    scrapy crawl myspider   启动爬虫
    scrapy check 检查
    scrapy list
    
    scrapy fetch <url> 下载页面
    $ scrapy fetch --nolog http://www.example.com/some/page.html
    [ ... html content here ... ]
    $ scrapy fetch --nolog --headers http://www.example.com/
    {'Accept-Ranges': ['bytes'],
     'Age': ['1263   '],
     'Connection': ['close     '],
     'Content-Length': ['596'],
     'Content-Type': ['text/html; charset=UTF-8'],
     'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],
     'Etag': ['"573c1-254-48c9c87349680"'],
     'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],
     'Server': ['Apache/2.2.3 (CentOS)']}

     scrapy runspider <spider_file.py>  在Python文件中运行自包含的蜘蛛，而无需创建项目。